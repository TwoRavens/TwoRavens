{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct, random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "# import networkx.algorithms.isomorphism.vf2userfunc as vf2\n",
    "# from networkx.algorithms import isomorphism\n",
    "from VF2 import GraphMatcher\n",
    "import random\n",
    "from networkx.generators import gnm_random_graph\n",
    "from collections import OrderedDict\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "from sklearn.datasets import make_classification\n",
    "import functools\n",
    "import sys, os\n",
    "from os.path import join\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def nodeID2node(nodeID, G):\n",
    "    \"\"\"\n",
    "    takes a nodeID and returns a node in the graph G\n",
    "    \"\"\"\n",
    "    node=None\n",
    "    for n,d in G.nodes_iter(data=True):\n",
    "        if d['nodeID']==nodeID:\n",
    "            node=n\n",
    "            break\n",
    "    return node\n",
    "\n",
    "def node2nodeID(node, G):\n",
    "    \"\"\"\n",
    "    takes a node and returns a nodeID for that node in the graph G\n",
    "    \"\"\"\n",
    "    return G.node[node]['nodeID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define graph matching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNodeMatch(g1node, g2node, node_map):\n",
    "    g1node = g1node['nodeID']\n",
    "    g2node = g2node['nodeID']\n",
    "    if g1node in node_map:\n",
    "        return node_map[g1node]==g2node\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "class GraphMatching:\n",
    "    def __init__(self, G1, G2, node_map):\n",
    "        self.G1 = G1\n",
    "        self.G2 = G2\n",
    "        self.node_map = node_map\n",
    "        \n",
    "    def match(self, timeLimit=30):\n",
    "        G1_max = max(nx.connected_component_subgraphs(self.G1), key=len)\n",
    "        G2_max = max(nx.connected_component_subgraphs(self.G2), key=len)\n",
    "        \n",
    "        GM = GraphMatcher(G1_max, G2_max, node_match=functools.partial(checkNodeMatch, node_map=self.node_map))\n",
    "        GM.mapping = node_map\n",
    "        GM.subgraph_is_isomorphic(timeLimit=timeLimit)\n",
    "        self.mapping = GM.mapping\n",
    "    \n",
    "    def predict(self, testDataDf):\n",
    "        # make a dictionary from the node mapping beteen G1 and G2\n",
    "        l_g1 = list(map(functools.partial(node2nodeID, G=self.G1), self.mapping.keys()))\n",
    "        l_g2 = list(map(functools.partial(node2nodeID, G=self.G2), self.mapping.values()))\n",
    "        d_g1_g2 = dict(zip(l_g1, l_g2))\n",
    "        \n",
    "        lookup = lambda a, D: D[a] if a in D else 1\n",
    "        testDataDf['G2.nodeID'] = testDataDf['G1.nodeID'].apply(functools.partial(lookup, D=d_g1_g2))\n",
    "        return testDataDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building graph matching model ...\n"
     ]
    }
   ],
   "source": [
    "print('building graph matching model ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = \"../../data\"\n",
    "rawDataDir = os.path.join(dataDir, \"raw_data\")\n",
    "rootDir = os.path.join(dataDir, \"..\")\n",
    "assert os.path.exists(dataDir)\n",
    "assert os.path.exists(rawDataDir)\n",
    "assert os.path.exists(rootDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the graphs ...\n"
     ]
    }
   ],
   "source": [
    "# read the graphs\n",
    "print('reading the graphs ...')\n",
    "G1 = nx.read_gml(join(rawDataDir, 'G1.gml'))\n",
    "G2 = nx.read_gml(join(rawDataDir, 'G2.gml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 1000 5521\n",
      "G2 755 5139\n"
     ]
    }
   ],
   "source": [
    "print('G1',len(G1.nodes()), len(G1.edges()))\n",
    "print('G2',len(G2.nodes()), len(G2.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train data (known node mappings) and priming the graph matching process ...\n"
     ]
    }
   ],
   "source": [
    "print('reading train data (known node mappings) and priming the graph matching process ...')\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "trainTargetsDF = pd.read_csv(join(dataDir, 'trainTargets.csv'), index_col=0)\n",
    "# print(trainDataDf.shape, trainTargetsDF.shape)\n",
    "# print(trainDataDf.head())\n",
    "# print(trainTargetsDF.head())\n",
    "df = pd.concat([trainDataDf,trainTargetsDF], axis=1)\n",
    "df = df[['G1.nodeID', 'G2.nodeID']]\n",
    "node_map = pd.Series(df['G2.nodeID'].values, index=df['G1.nodeID']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing the graph matching ...\n"
     ]
    }
   ],
   "source": [
    "# align the graphs\n",
    "print('performing the graph matching ...')\n",
    "gm = GraphMatching(G1, G2, node_map=node_map)\n",
    "gm.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model on trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying the model on training data (known mappings) ...\n"
     ]
    }
   ],
   "source": [
    "print('trying the model on training data (known mappings) ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data: 0.695364238411\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on train data\n",
    "train_performance = OrderedDict()\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "prediction = gm.predict(trainDataDf)['G2.nodeID']\n",
    "train_truth = pd.read_csv(join(dataDir, 'trainTargets.csv'), index_col=0)['G2.nodeID']\n",
    "accuracy = accuracy_score(train_truth, prediction)\n",
    "\n",
    "train_performance = OrderedDict([\n",
    "    ('train', OrderedDict([\n",
    "        ('score', OrderedDict([\n",
    "                ('metric', 'accuracy'),\n",
    "                ('value', accuracy)])\n",
    "        )\n",
    "    ]))\n",
    "])\n",
    "\n",
    "print('accuracy on training data:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit predictions on testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying the model on test data (unknown mappings ...)\n"
     ]
    }
   ],
   "source": [
    "print('applying the model on test data (unknown mappings ...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions on testData (assuming that testData is available) ...\n",
      "1. reading testData ...\n",
      "2. making predictions ...\n",
      "3. formatting and saving testTargets.csv\n"
     ]
    }
   ],
   "source": [
    "print('making predictions on testData (assuming that testData is available) ...')\n",
    "try:\n",
    "    print('1. reading testData ...')\n",
    "    testDataDf = pd.read_csv(join(dataDir, 'testData.csv'), index_col=0)\n",
    "    print('2. making predictions ...')\n",
    "    prediction = pd.DataFrame(gm.predict(testDataDf)['G2.nodeID'])\n",
    "    print('3. formatting and saving testTargets.csv')\n",
    "    prediction.insert(0, 'graph', 'G2.gml')\n",
    "    # print(prediction.head())\n",
    "    prediction.to_csv('testTargets.csv')\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testData is unavailable. Cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute performance on testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_performance = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing performance on testData (assuming the testTargets is available) ...\n",
      "1. reading testTargets...\n",
      "2. reading predictions ...\n",
      "3. computing accuracy ...\n",
      "performance on test data: 0.683774834437\n",
      "4. saving the performance score...\n"
     ]
    }
   ],
   "source": [
    "print('computing performance on testData (assuming the testTargets is available) ...')\n",
    "try:\n",
    "    print('1. reading testTargets...')# read the y_truth\n",
    "    y_truth = pd.read_csv(join(dataDir, 'testTargets.csv'))['G2.nodeID']\n",
    "    print('2. reading predictions ...')\n",
    "    # read the y_predicted\n",
    "    y_predicted = pd.read_csv('testTargets.csv')['G2.nodeID']\n",
    "    print('3. computing accuracy ...')\n",
    "    accuracy = accuracy_score(y_truth, y_predicted)\n",
    "    print('performance on test data:',accuracy)\n",
    "    print('4. saving the performance score...')\n",
    "    test_performance = OrderedDict([\n",
    "        ('test', OrderedDict([\n",
    "            ('score', OrderedDict([\n",
    "                    ('metric', 'accuracy'),\n",
    "                    ('value', accuracy)])\n",
    "            )\n",
    "        ]))\n",
    "    ])\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testTargets is unavailable. cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train\": {\n",
      "    \"score\": {\n",
      "      \"metric\": \"accuracy\",\n",
      "      \"value\": 0.695364238410596\n",
      "    }\n",
      "  },\n",
      "  \"test\": {\n",
      "    \"score\": {\n",
      "      \"metric\": \"accuracy\",\n",
      "      \"value\": 0.6837748344370861\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "overall_performance = OrderedDict()\n",
    "overall_performance.update(train_performance)\n",
    "overall_performance.update(test_performance)\n",
    "\n",
    "with open('performance.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(overall_performance, f, indent=2)\n",
    "print(json.dumps(overall_performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:49_facebook_seed]",
   "language": "python",
   "name": "conda-env-49_facebook_seed-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
