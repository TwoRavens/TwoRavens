{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct, random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import networkx.algorithms.isomorphism.vf2userfunc as vf2\n",
    "import random\n",
    "from networkx.generators import gnm_random_graph\n",
    "from collections import OrderedDict\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "from sklearn.datasets import make_classification\n",
    "import functools\n",
    "import sys, os\n",
    "from os.path import join\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define graph matching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def nodeID2node(nodeID, G):\n",
    "    \"\"\"\n",
    "    takes a nodeID and returns a node in the graph G\n",
    "    \"\"\"\n",
    "    node=None\n",
    "    for n,d in G.nodes_iter(data=True):\n",
    "        if d['nodeID']==nodeID:\n",
    "            node=n\n",
    "            break\n",
    "    return node\n",
    "\n",
    "def node2nodeID(node, G):\n",
    "    \"\"\"\n",
    "    takes a node and returns a nodeID for that node in the graph G\n",
    "    \"\"\"\n",
    "    return G.node[node]['nodeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphMatching:\n",
    "    def __init__(self, G1, G2):\n",
    "        self.G1 = G1\n",
    "        self.G2 = G2\n",
    "        \n",
    "    def match(self):\n",
    "        G1_max = max(nx.connected_component_subgraphs(self.G1), key=len)\n",
    "        G2_max = max(nx.connected_component_subgraphs(self.G2), key=len)\n",
    "        \n",
    "        graphMatcher = vf2.GraphMatcher(G1_max, G2_max)\n",
    "        graphMatcher.subgraph_is_isomorphic()\n",
    "        # get the full/max node mapping\n",
    "        self.mapping = graphMatcher.mapping\n",
    "        \n",
    "    def predict(self, testDataDf):\n",
    "        # make a dictionary from the node mapping beteen G1 and G2\n",
    "        l_g1 = list(map(functools.partial(node2nodeID, G=self.G1), self.mapping.keys()))\n",
    "        l_g2 = list(map(functools.partial(node2nodeID, G=self.G2), self.mapping.values()))\n",
    "        d_g1_g2 = dict(zip(l_g1, l_g2))\n",
    "        \n",
    "        lookup = lambda a, D: D[a]\n",
    "        testDataDf['G2.nodeID'] = testDataDf['G1.nodeID'].apply(functools.partial(lookup, D=d_g1_g2))\n",
    "        return testDataDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('building graph matching model ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = \"../../data\"\n",
    "rawDataDir = os.path.join(dataDir, \"raw_data\")\n",
    "rootDir = os.path.join(dataDir, \"..\")\n",
    "assert os.path.exists(dataDir)\n",
    "assert os.path.exists(rawDataDir)\n",
    "assert os.path.exists(rootDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the graphs\n",
    "G1 = nx.read_gml(join(rawDataDir, 'G1.gml'))\n",
    "G2 = nx.read_gml(join(rawDataDir, 'G2.gml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# align the graphs\n",
    "gm = GraphMatching(G1, G2)\n",
    "gm.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model on trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trying the model on training data ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on train data\n",
    "train_performance = OrderedDict()\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "prediction = gm.predict(trainDataDf)['G2.nodeID']\n",
    "train_truth = pd.read_csv(join(dataDir, 'trainTargets.csv'), index_col=0)['G2.nodeID']\n",
    "accuracy = accuracy_score(train_truth, prediction)\n",
    "\n",
    "train_performance = OrderedDict([\n",
    "    ('train', OrderedDict([\n",
    "        ('score', OrderedDict([\n",
    "                ('metric', 'accuracy'),\n",
    "                ('value', accuracy)])\n",
    "        )\n",
    "    ]))\n",
    "])\n",
    "\n",
    "print('accuracy on training data:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit predictions on testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('making predictions on testData (assuming that testData is available) ...')\n",
    "try:\n",
    "    print('1. reading testData ...')\n",
    "    testDataDf = pd.read_csv(join(dataDir, 'testData.csv'), index_col=0)\n",
    "    print('2. making predictions ...')\n",
    "    prediction = pd.DataFrame(gm.predict(testDataDf)['G2.nodeID'])\n",
    "    print('3. formatting and saving testTargets.csv')\n",
    "    prediction.insert(0, 'graph', 'G2.gml')\n",
    "    # print(prediction.head())\n",
    "    prediction.to_csv('testTargets.csv')\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testData is unavailable. Cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute performance on testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_performance = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('computing performance on testData (assuming the testTargets is available) ...')\n",
    "try:\n",
    "    print('1. reading testTargets...')# read the y_truth\n",
    "    y_truth = pd.read_csv(join(dataDir, 'testTargets.csv'))['G2.nodeID']\n",
    "    print('2. reading predictions ...')\n",
    "    # read the y_predicted\n",
    "    y_predicted = pd.read_csv('testTargets.csv')['G2.nodeID']\n",
    "    print('3. computing accuracy ...')\n",
    "    accuracy = accuracy_score(y_truth, y_predicted)\n",
    "    print('performance on test data:',accuracy)\n",
    "    print('4. saving the performance score...')\n",
    "    test_performance = OrderedDict([\n",
    "        ('test', OrderedDict([\n",
    "            ('score', OrderedDict([\n",
    "                    ('metric', 'accuracy'),\n",
    "                    ('value', accuracy)])\n",
    "            )\n",
    "        ]))\n",
    "    ])\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testTargets is unavailable. cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_performance = OrderedDict()\n",
    "overall_performance.update(train_performance)\n",
    "overall_performance.update(test_performance)\n",
    "\n",
    "with open('performance.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(overall_performance, f, indent=2)\n",
    "print(json.dumps(overall_performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
