{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct, random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import networkx.algorithms.isomorphism.vf2userfunc as vf2\n",
    "import random\n",
    "from networkx.generators import gnm_random_graph\n",
    "from collections import OrderedDict\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "from sklearn.datasets import make_classification\n",
    "import functools\n",
    "import sys, os\n",
    "from os.path import join\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph matching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def nodeID2node(nodeID, G):\n",
    "    \"\"\"\n",
    "    takes a nodeID and returns a node in the graph G\n",
    "    \"\"\"\n",
    "    node=None\n",
    "    for n,d in G.nodes_iter(data=True):\n",
    "        if d['nodeID']==nodeID:\n",
    "            node=n\n",
    "            break\n",
    "    return node\n",
    "\n",
    "def node2nodeID(node, G):\n",
    "    \"\"\"\n",
    "    takes a node and returns a nodeID for that node in the graph G\n",
    "    \"\"\"\n",
    "    return G.node[node]['nodeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatching:\n",
    "    def __init__(self, G1, G2):\n",
    "        self.G1 = G1\n",
    "        self.G2 = G2\n",
    "        \n",
    "    def match(self):\n",
    "        G1_max = max(nx.connected_component_subgraphs(self.G1), key=len)\n",
    "        G2_max = max(nx.connected_component_subgraphs(self.G2), key=len)\n",
    "        \n",
    "        graphMatcher = vf2.GraphMatcher(G1_max, G2_max)\n",
    "        print(graphMatcher.subgraph_is_isomorphic())\n",
    "        # get the full/max node mapping\n",
    "        self.mapping = graphMatcher.mapping\n",
    "        \n",
    "    def predict(self, testDataDf):\n",
    "        # make a dictionary from the node mapping\n",
    "        l_g1 = list(map(functools.partial(node2nodeID, G=self.G1), self.mapping.keys()))\n",
    "        l_g2 = list(map(functools.partial(node2nodeID, G=self.G2), self.mapping.values()))\n",
    "        d_g1_g2 = dict(zip(l_g1, l_g2))\n",
    "        \n",
    "        lookup = lambda a, D: D[a]\n",
    "        testDataDf['G2.nodeID'] = testDataDf['G1.nodeID'].apply(functools.partial(lookup, D=d_g1_g2))\n",
    "        return testDataDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = \"../../data\"\n",
    "rawDataDir = os.path.join(dataDir, \"raw_data\")\n",
    "assert os.path.exists(dataDir)\n",
    "assert os.path.exists(rawDataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the graphs\n",
    "G1 = nx.read_gml(join(rawDataDir, 'G1.gml'))\n",
    "G2 = nx.read_gml(join(rawDataDir, 'G2.gml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# align the graphs\n",
    "gm = GraphMatching(G1, G2)\n",
    "gm.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on train data\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "prediction = gm.predict(trainDataDf)['G2.nodeID']\n",
    "truth = pd.read_csv(join(dataDir, 'trainTargets.csv'), index_col=0)['G2.nodeID']\n",
    "accuracy = accuracy_score(truth, prediction)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train and test data. Train data gives us the known mapping btween the nodes\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "# gather g1_subset_nodes\n",
    "trainDataDf['G1.node'] = trainDataDf['G1.nodeID'].apply(functools.partial(nodeID2node, G=G1)) # map nodeIDs to actual nodes in trainData\n",
    "g1_nodes = list(trainDataDf['G1.node'].values) # get the nodes in trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GraphMatching(G1, G2)\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "gm.fit(trainDataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if the subset of G1 isomorphic to G2 (ideally, they should be)\n",
    "gm = vf2.GraphMatcher(G1, G2)\n",
    "print(gm.subgraph_is_isomorphic())\n",
    "# get the full/max node mapping\n",
    "mapping = gm.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the train and test data. Train data gives us the known mapping btween the nodes\n",
    "trainDataDf = pd.read_csv(join(dataDir, 'trainData.csv'), index_col=0)\n",
    "testDataDf = pd.read_csv(join(dataDir, 'testData.csv'), index_col=0)\n",
    "\n",
    "# gather the nodes of G1\n",
    "trainDataDf['G1.node'] = trainDataDf['G1.nodeID'].apply(functools.partial(nodeID2node, G=G1)) # map nodeIDs to actual nodes in trainData\n",
    "g1_nodes = list(trainDataDf['G1.node'].values) # get the nodes in trainData\n",
    "testDataDf['G1.node'] = testDataDf['G1.nodeID'].apply(functools.partial(nodeID2node, G=G1)) # map nodeIDs to actual nodes in testData\n",
    "g1_nodes = g1_nodes + (list(testDataDf['G1.node'].values)) # add the nodes from testData\n",
    "# print(g1_nodes)\n",
    "\n",
    "# induce a subgraph of G1 with the nodes in the train and test data\n",
    "G1_sub = G1.subgraph(g1_nodes)\n",
    "G1_sub = max(nx.connected_component_subgraphs(G1_sub), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n",
      "5138\n"
     ]
    }
   ],
   "source": [
    "print(len(G1_sub.nodes()))\n",
    "print(len(G1_sub.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if the subset of G1 isomorphic to G2 (ideally, they should be)\n",
    "gm = vf2.GraphMatcher(G1_sub, G2)\n",
    "print(gm.subgraph_is_isomorphic())\n",
    "# get the full/max node mapping\n",
    "mapping = gm.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a dictionary from the node mapping\n",
    "l_g1 = list(map(functools.partial(node2nodeID, G=G1), gm.mapping.keys()))\n",
    "l_g2 = list(map(functools.partial(node2nodeID, G=G2), gm.mapping.values()))\n",
    "d_g1_g2 = dict(zip(l_g1, l_g2))\n",
    "# print(d_g1_g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the prediction on the testTargets using the mapping\n",
    "lookup = lambda a, D: D[a]\n",
    "testDataDf['G2.nodeID'] = testDataDf['G1.nodeID'].apply(functools.partial(lookup, D=d_g1_g2))\n",
    "pd.DataFrame(testDataDf['G2.nodeID']).to_csv('testTargets_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate the pipeline\n",
    "Note: this section will not be applicable to performer systems as they will not have access to the truth data. This is only for the baseline systems to obtian a reference score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the y_truth\n",
    "y_truth = pd.read_csv(join(dataDir, 'testTargets.csv'))['G2.nodeID']\n",
    "# read the y_predicted\n",
    "y_predicted = pd.read_csv('testTargets_predicted.csv')['G2.nodeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy score\n",
    "score = {'accuracy':accuracy_score(y_truth, y_predicted)}\n",
    "print(score)\n",
    "# write to score file\n",
    "with open('performance.json', 'w') as outfile:\n",
    "    json.dump(score, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
